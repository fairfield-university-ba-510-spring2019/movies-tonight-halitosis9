{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies Tonight Part 3: SQL DML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql sqlite:///Movies.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Load the `DATASET.csv` file into the `Movies.db` database.**  \n",
    "    - Import the CSV file to create a new table called `DATASET`. Follow the example [here](http://www.sqlitetutorial.net/sqlite-import-csv/).\n",
    "    - Use a [`PRAGMA table-info` pseudo-query](https://www.sqlite.org/pragma.html#pragma_table_info) to inspect the design of the new table. [How are we going to handle dates](https://www.sqlite.org/datatype3.html)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Populate the tables with data.**  \n",
    "\n",
    "    - Use `INSERT ... SELECT ...` queries to extract data from `DATASET` for each table of your other tables. \n",
    "    - Start with the strong entities before moving on to the weak ones. Be sure to always select distinct     values. \n",
    "    - Foreign Keys get special treatment. You will have to use JOINs to pick up the PKs from the other side of the relationships. (As in Part 1, use the fact that movie names, theater names, and people names are always unique in our source data. That way you can use then for the JOIN columns. \n",
    "    - If you have to start over, then rerun your DDL queries from Part 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Check your work.**  \n",
    "There are 9 theaters, 23 movies, 152 artists, 131 shows, and 161 credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Now check the source data.**  \n",
    "There are actually 13 duplicate rows in the original source data! Can you spot them? Write a SQL query that counts how many times each (MTitle, TName, Showtime, CCode, and CName) appears. Which ones appear more than once?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Drop the `DATASET` table.**  \n",
    "We don't need it anymore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Save, commit, and push your work to GitHub.**  \n",
    "Use the commit summary comment \"Completed Part 3\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
